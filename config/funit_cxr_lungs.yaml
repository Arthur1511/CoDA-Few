# Copyright (C) 2017 NVIDIA Corporation.  All rights reserved.
# Licensed under the CC BY-NC-SA 4.0 license (https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode).

# logger options
image_save_iter: 2500         # How often do you want to save output images during training
image_display_iter: 500       # How often do you want to display output images during training
val_iter: 500                 # How often do you want to compute jaccard score
snapshot_save_iter: 5000      # How often do you want to save trained models
log_iter: 100                 # How often do you want to log the training stats
display_size: 4               # How many images do you want to display each time

# optimization options
max_iter: 10000               # maximum number of training iterations
batch_size: 3                 # batch size
beta1: 0.5                    # Adam parameter
beta2: 0.999                  # Adam parameter
init: kaiming                 # initialization [gaussian/kaiming/xavier/orthogonal]
lr: 0.0001                    # initial learning rate
weight_decay: 0.0001          # weight decay
lr_policy: constant           # learning rate scheduler
step_size: 3000               # how often to decay learning rate
gamma: 0.5                    # how much to decay learning rate
gan_w: 1                      # weight of adversarial loss for image translation
sup_w: 1                      # weight of supervised loss
recon_x_w: 10                 # weight of image reconstruction loss
recon_s_w: 1                  # weight of style reconstruction loss
recon_c_w: 1                  # weight of content reconstruction loss
recon_x_cyc_w: 1              # weight of explicit style augmented cycle consistency loss
vgg_w: 0                      # weight of domain-invariant perceptual loss
lr_gen: 0.0001                # learning rate for the generator
lr_dis: 0.0001                # learning rate for the discriminator
fm_w: 1                       # weight on distance between gan features of style and translated image
r_w: 0.1                      # weight of image reconstruction loss


# fewshot model options
fewshot_gen:
  nf: 64                      # number of base filters in the generator
  n_res_blks: 2               # number of residual blocks in content encoder/decoder
  nf_mlp: 256                 # number of base filters in MLP module
  latent_dim: 64              # dimension of the latent code for the class model
  n_mlp_blks: 3               # number of mlp blocks
  n_downs_content: 2          # number of downsampling layers in content encoder
  n_downs_class: 4            # number of downsampling layers in class model encoder

fewshot_dis:
  nf: 64                      # base number of filters
  n_res_blks: 10              # number of residual blocks in the discriminator
  num_classes: 4              # number of classes in the training set

sup:
  dim: 128                    # number of filters in the bottommost layer
  
# data options
n_datasets: 4                                       # number of datasets used in training
n_classes: 2                                        # number of classes in supervised task
input_dim: 1                                        # number of image channels [1/3]
num_workers: 4                                      # number of data loading threads
resize_height: 284                                  # first resize image to this height
resize_width: 284                                   # first resize image to this width
crop_height: 256                                    # random crop image of this height
crop_width: 256                                     # random crop image of this width
data_root: ../../hugo/GANs/CoDAGAN_Semi/datasets/CXR_lungs/ # dataset folder location
datasets_train: ['A','B','C','D']                       # datasets used in train
datasets_test: ['E','F', 'G']                                # datasets used in test
label_use_train: 1|1|1|1
label_use_test: 0|0|0
